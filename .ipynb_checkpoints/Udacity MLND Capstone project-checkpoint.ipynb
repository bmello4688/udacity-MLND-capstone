{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Project Definition</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Domain Background</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the field of instrumental analytical chemistry, there are many techniques for identifying unknown substances. This field is primarily researched for the detection of explosives, drugs and chemical weapons, however, there are many other applications for it. In the healthcare field, researchers are using it to detect cancer and diseases.\n",
    "Chromatography is a method by which a substance is separated into different components and split across time. For example, if you sample a mixture that is made up of multiple substances you could separate those substances and detect them individually with chromatography. One method of chromatography is using what is called a column. This device is what will separate out the components of a mixture, however, it is extremely slow. It takes minutes to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass spectrometry is the technique of identifying the chemical structure of a substance by separating ions into differing mass and charge. The three essential components of a mass spectrometer are the ion source, the mass analyzer, and the detector. The ionizer ionizes the sampled substance. The analyzer sorts and separates the ions by mass and charge. The detector measures or counts the separated ions. Ions can be displayed as a histogram of mass-to-charge ratio(m/z) or can be displayed across time to see line curves where the peaks would be where the max quantity of ions were detected. There are many different techniques for each component in performing the identification of substances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular analytical technique today is ion-mobility spectrometry (IMS). This technique separates and identifies ionized molecules based on their mobility within a carrier gas. It is extremely fast and takes milliseconds to achieve a result, but it is less sensitive than other techniques. This technique is very popular because you can make an IMS device for relative low cost compared to other techniques and the device can be small enough to be hand-held."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final technique that we will discuss is triple quadrupole mass spectrometry (TQMS). This is a tandem mass spectrometry technique, which just means it has two analyzers. The components in order are the ion source, a quadrupole mass analyzer, a quadrupole that acts as a collision cell to fragment the molecules entering it, a second analyzer that analyzes the resulting fragments, and finally the detector. The quadrupole works by creating an electro-magnetic field that separates the ions and makes them follow a trajectory based on their mass-to-charge ratio (m/z). This technique in theory is the most sensitive and will achieve results in seconds. These devices tend to be very expensive and large. This is the device a team and I are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above techniques discussed can all be combined to solve problems depending on the application. There are trade-offs that must be made for each technique. Cost and weight are always a major factor. In some cases, the science is not well understood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My team and I are currently working on a triple quad mass spectrometer that is cheaper and smaller so that we can address new markets and applications that TQMS was unable to address previously. Our current instrument displays mass-to-charge ratios over time. We have in the past used peak thresholds to determine what is a detected substance. This technique only gives us an accuracy of 40% with a very high rate of false positives. We are trying to achieve an accuracy of 90% with no more than a 2% false positive rate. We have talked about adding some filtering techniques, but there will be a tradeoff in time and cost. We need to complete our analysis in under 10 seconds. Ideally, we can solve our problem with purely algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sets and Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets that will be used in this project were generated from collected samples from our instrument. The instrument was sent out for testing and 12 different substances were tested. The data files we got back are the results from that testing. The datasets are generated from these data files. The datasets have been modified to abstract out any sensitive details such as the substance name and mass pairs. Most importantly the intensities are all generated to mimic the shape of the collected data. The data has also been filtered to remove any malformed data because of a hardware or any other error. There is no proprietary data associated with this project. The model that will be built will need to be re-trained on the actual proprietary dataset to have it work with our instrument. The generated data should be more than adequate in evaluating a model. In most cases, I have between 50 and 80 samples for each substance I am testing for. I realize that this may not be enough, but I am also trying to gauge how many samples will be needed if extending out the substance library. If a compound is performing poorly from lack of samples I will remove it from the test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data file consists of multiple components. First, there will be a mass pair transition id. A mass pair transition consists of an ion charge (+ or -), parent mass, a daughter mass, and collision energy i.e. +123->456(78). The ion charge is from the ion source, the parent mass is from the first quad, the daughter mass is from the third quad and the collision energy is applied at the second quad. Instead of seeing this transition you will see a number 0 to n-1 where n is the total quantity of specified transitions (i.e. n=51). After the id there will be a sample id associated to the dataset, a comment field which will specify if another substance was combined the tested for substance, and what substrate it was sampled on. Substrate could have the value direct, or a harvest code like Perf5. Direct means the substance was inserted into the instrument through a syringe. Direct should be the most stable result. If the substance was harvested off material Perf5 that means the substance was applied to the material and then swiped off with one of our swabs. Theoretically when a substance is harvested it should measure lower ions than direct because you may not of collected the entire amount of the substance. After the substrate field, there will be detection field and an association field. The detection field will have an array of numbers specifying what compounds are detected within that dataset. The association field will specify what mass pairs are associated to which compounds according to our chemist, for example mass pair 1 is associated to compounds [1,3]. After the associated field there will be a height, width, area, and position of the mass pair peak. These values are acquired by applying a smoothing filter to reduce the noise of the signal. Finally, there will be a time series of intensities over a specified number of time steps or scans (i.e. 23). For now, the scan count is fixed to 23, however, in the future it would be better to have scan count be variable in case we want to stop early. So, for each data file you would have that structure per row times the amount of transitions for example 51x33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples:  641\n",
      "Max number of mass pairs:  51\n"
     ]
    }
   ],
   "source": [
    "#Load datasets\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "os.chdir(\"./data\")\n",
    "\n",
    "samples = []\n",
    "count = 0\n",
    "max_mass_pair_count = 0\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    data_frame = pd.read_csv(file)\n",
    "    count += 1\n",
    "    mass_pair_count = len(data_frame)\n",
    "    max_mass_pair_count = mass_pair_count if mass_pair_count > max_mass_pair_count else max_mass_pair_count\n",
    "    samples.append(data_frame)\n",
    "    \n",
    "os.chdir(\"..\")\n",
    "\n",
    "merged_data_set = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "print(\"Number of Samples: \", count)\n",
    "print(\"Max number of mass pairs: \", max_mass_pair_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_pair_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>substrate</th>\n",
       "      <th>detection</th>\n",
       "      <th>association</th>\n",
       "      <th>peak_height</th>\n",
       "      <th>peak_widthpeak_area</th>\n",
       "      <th>peak_position</th>\n",
       "      <th>timestep_01</th>\n",
       "      <th>...</th>\n",
       "      <th>timestep_14</th>\n",
       "      <th>timestep_15</th>\n",
       "      <th>timestep_16</th>\n",
       "      <th>timestep_17</th>\n",
       "      <th>timestep_18</th>\n",
       "      <th>timestep_19</th>\n",
       "      <th>timestep_20</th>\n",
       "      <th>timestep_21</th>\n",
       "      <th>timestep_22</th>\n",
       "      <th>timestep_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30037</td>\n",
       "      <td>Positive Control</td>\n",
       "      <td>None</td>\n",
       "      <td>[21, 0, 18, 4]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>477.454417</td>\n",
       "      <td>6.386572</td>\n",
       "      <td>1823.300717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.077684</td>\n",
       "      <td>12.398664</td>\n",
       "      <td>1170.550038</td>\n",
       "      <td>13.094119</td>\n",
       "      <td>10.633276</td>\n",
       "      <td>8.600405</td>\n",
       "      <td>5.765087</td>\n",
       "      <td>7.052225</td>\n",
       "      <td>10.963616</td>\n",
       "      <td>3.839209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mass_pair_id  sample_id           comment substrate       detection  \\\n",
       "0             0      30037  Positive Control      None  [21, 0, 18, 4]   \n",
       "\n",
       "  association  peak_height  peak_widthpeak_area  peak_position  timestep_01  \\\n",
       "0        [10]   477.454417             6.386572    1823.300717          0.0   \n",
       "\n",
       "      ...       timestep_14  timestep_15  timestep_16  timestep_17  \\\n",
       "0     ...         12.077684    12.398664  1170.550038    13.094119   \n",
       "\n",
       "   timestep_18  timestep_19  timestep_20  timestep_21  timestep_22  \\\n",
       "0    10.633276     8.600405     5.765087     7.052225    10.963616   \n",
       "\n",
       "   timestep_23  \n",
       "0     3.839209  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_set.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compounds\n",
       "[10]              58\n",
       "[13]              68\n",
       "[14]              36\n",
       "[15]              68\n",
       "[18]              77\n",
       "[19]               4\n",
       "[21, 0, 18, 4]    75\n",
       "[21]              79\n",
       "[22]              79\n",
       "[3]               19\n",
       "[7]                9\n",
       "[8]               58\n",
       "Name: Sample count per compound, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = (merged_data_set.groupby(['detection']).count()/max_mass_pair_count)['mass_pair_id']\n",
    "\n",
    "results.index.name = 'Compounds'\n",
    "\n",
    "results.name = 'Sample count per compound'\n",
    "\n",
    "results.round() # in case sample file has extra mass pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compound 7 and 19 do not have enough samples. I will perform data analysis anyways. I will consider dropping later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can only be benchmarked against the previous solution which yields a total accuracy of 40%. Minimum peak height was the only threshold where it was manually set based on internal lab testing. for example, compound 1 could have a minimum height threshold of 1600 ion counts. If the peak signal was below this amount it was deemed noise and ignored. If it was above it would be part of some additional logic that required all associated mass pairs to be above their limits to raise a substance detection alert. Below is most of a confusion matrix, but TNR is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Compound ID</th>\n",
    "<th>TPR</th>\n",
    "<th>FPR</th>\n",
    "<th>FNR</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Compound 3</td>\n",
    "<td>5.00%</td>\n",
    "<td>4.55%</td>\n",
    "<td>95.00%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 4</td>\n",
    "<td>30.34%</td>\n",
    "<td>52.81%</td>\n",
    "<td>32.58%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 7</td>\n",
    "<td>0.00%</td>\n",
    "<td>87.50%</td>\n",
    "<td>12.50%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 8</td>\n",
    "<td>13.33%</td>\n",
    "<td>20.00%</td>\n",
    "<td>66.67%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 10</td>\n",
    "<td>12.31%</td>\n",
    "<td>7.69%</td>\n",
    "<td>86.15%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 13</td>\n",
    "<td>0.00%</td>\n",
    "<td>21.21%</td>\n",
    "<td>84.85%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 14</td>\n",
    "<td>5.00%</td>\n",
    "<td>0.00%</td>\n",
    "<td>95.00%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 15</td>\n",
    "<td>20.37%</td>\n",
    "<td>12.96%</td>\n",
    "<td>68.52%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 18</td>\n",
    "<td>59.65%</td>\n",
    "<td>28.95%</td>\n",
    "<td>14.91%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 19</td>\n",
    "<td>20.00%</td>\n",
    "<td>70.00%</td>\n",
    "<td>50.00%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 21</td>\n",
    "<td>72.90%</td>\n",
    "<td>26.17%</td>\n",
    "<td>0.93%</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Compound 22</td>\n",
    "<td>70.27%</td>\n",
    "<td>17.12%</td>\n",
    "<td>15.32%</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: ~40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our models, we should be using a weighted accuracy metric such as fbeta_score and a confusion matrix to see our false positive rate. According to our requirements we could miss a detection 10% of the time if we have a false positive rate below 2%. Since it is more important to be precise than have high recall we should have our beta be a value of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mass_pair_id', 'sample_id', 'peak_height', 'peak_widthpeak_area',\n",
       "       'peak_position', 'timestep_01', 'timestep_02', 'timestep_03',\n",
       "       'timestep_04', 'timestep_05', 'timestep_06', 'timestep_07',\n",
       "       'timestep_08', 'timestep_09', 'timestep_10', 'timestep_11',\n",
       "       'timestep_12', 'timestep_13', 'timestep_14', 'timestep_15',\n",
       "       'timestep_16', 'timestep_17', 'timestep_18', 'timestep_19',\n",
       "       'timestep_20', 'timestep_21', 'timestep_22', 'timestep_23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_by_detection = merged_data_set.groupby(['detection']).mean()\n",
    "\n",
    "mean_by_detection[['peak_height', 'peak_width', 'peak_area', 'peak_position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
